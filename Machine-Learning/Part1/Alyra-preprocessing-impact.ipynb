{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3554048",
   "metadata": {},
   "source": [
    "# Impact du preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab378a0",
   "metadata": {},
   "source": [
    "## Rappels \n",
    "\n",
    "**Le preprocessing est une étape cruciale dans le pipeline de machine learning.**  \n",
    "Il permet de préparer les données pour les modèles, en assurant que les caractéristiques sont sur une échelle comparable et que les données sont propres et prêtes à être utilisées.\n",
    "\n",
    "**Certains modèles sont plus impactés par le preprocessing que d'autres.**  \n",
    "Par exemple, les modèles basés sur des distances (comme les k-NN ou les SVM) sont très sensibles à l'échelle des données, tandis que les arbres de décision ne le sont pas autant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a87cf",
   "metadata": {},
   "source": [
    "### Règle mentale essentielle - Scaler :\n",
    "> **Si le modèle calcule une distance, un produit scalaire ou optimise par gradient → SCALE.**   \n",
    "> **S’il coupe avec des seuils (arbres) → pas besoin.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87ee01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Le modèle compare des points ? \n",
    "(distance, similarité, projection) ➡ Scaler obligatoire\n",
    "\n",
    "Exemples :\n",
    "- KNN\n",
    "\n",
    "- K-Means (clustering)\n",
    "\n",
    "- SVM\n",
    "\n",
    "- Régression logistique / linéaire\n",
    "\n",
    "- Réseaux de neurones (deep learning)\n",
    "\n",
    "- PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6004d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Le modèle fait des \"si X < seuil\" ?\n",
    "\n",
    "(découpe en branches) ➡ Pas besoin de scaling\n",
    "\n",
    "Exemples :\n",
    "\n",
    "- Decision Tree\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5cdfb",
   "metadata": {},
   "source": [
    "### Règle mentale - Encoding : \n",
    "> **si le modèle comprend une notion d’ordre → l’ordinal peut aller**  \n",
    "> **Sinon → One-Hot Encoding.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c5802",
   "metadata": {},
   "source": [
    "#### Le modèle utilise des distances ou des produits scalaires ?\n",
    "\n",
    "➡ One-Hot Encoding obligatoire.  \n",
    "➡ Pas d’encoding ordinal arbitraire. \n",
    "\n",
    "Exemples :\n",
    "- KNN\n",
    "\n",
    "- SVM\n",
    "\n",
    "- Régression logistique / linéaire\n",
    "\n",
    "- MLP\n",
    "\n",
    "- K-Means\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Si tu codes :\n",
    "```sh\n",
    "Chat = 0\n",
    "Chien = 1\n",
    "Lion = 2\n",
    "```\n",
    "➡ Le modèle croit que Lion > Chien > Chat, ce qui est faux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9602b",
   "metadata": {},
   "source": [
    "#### Le modèle est basé sur des arbres ?\n",
    "\n",
    "➡ Peut tolérer :\n",
    "\n",
    "- Ordinal Encoding\n",
    "\n",
    "- Label Encoding\n",
    "\n",
    "- (One-Hot reste sûr)\n",
    "\n",
    "Exemples :\n",
    "\n",
    "- Decision Tree\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting\n",
    "\n",
    "**Pourquoi ?**\n",
    "\n",
    "Les arbres coupent avec des seuils :\n",
    "```sh\n",
    "si catégorie <= 1\n",
    "```\n",
    "➡ Ils ne calculent pas de distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c973c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d867b",
   "metadata": {},
   "source": [
    "## Exemples d'impact du preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c37e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine, fetch_openml\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline # pour faire du chaining de transformations + modèle\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer # pour faire du preprocessing différent sur différentes colonnes\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281f57ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SCALING (Wine) : accuracy CV=5 ===\n",
      "KNN sans scaling     -> 0.691\n",
      "KNN + scaling        -> 0.949\n",
      "SVM RBF sans scaling -> 0.663\n",
      "SVM RBF + scaling    -> 0.983\n"
     ]
    }
   ],
   "source": [
    "# --------- 1) SCALING impact (réel, sklearn) : WINE ----------\n",
    "Xw, yw = load_wine(return_X_y=True)\n",
    "\n",
    "models_scaling = {\n",
    "    \"KNN sans scaling\": KNeighborsClassifier(5),\n",
    "    \"KNN + scaling\": make_pipeline(StandardScaler(), KNeighborsClassifier(5)),\n",
    "    \"SVM RBF sans scaling\": SVC(),\n",
    "    \"SVM RBF + scaling\": make_pipeline(StandardScaler(), SVC()),\n",
    "}\n",
    "print(\"\\n=== SCALING (Wine) : accuracy CV=5 ===\")\n",
    "for name, m in models_scaling.items():\n",
    "    acc = cross_val_score(m, Xw, yw, cv=5, scoring=\"accuracy\").mean()\n",
    "    print(f\"{name:20s} -> {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENCODING (Titanic) : accuracy CV=5 ===\n",
      "Données Titanic téléchargées depuis OpenML.\n",
      "KNN + OrdinalEnc     -> 0.488\n",
      "KNN + OneHotEnc      -> 0.791\n",
      "LogReg + OrdinalEnc  -> 0.658\n",
      "LogReg + OneHotEnc   -> 0.959\n"
     ]
    }
   ],
   "source": [
    "# --------- 2) ENCODING impact (réel via OpenML) : TITANIC ----------\n",
    "print(\"\\n=== ENCODING (Titanic) : accuracy CV=5 ===\")\n",
    "try:\n",
    "    titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "    print(\"Données Titanic téléchargées depuis OpenML.\")\n",
    "    \n",
    "    X, y = titanic.data, titanic.target\n",
    "    y = (y == \"1\").astype(int)  # survécu=1\n",
    "\n",
    "    cat = X.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns\n",
    "    num = X.columns.difference(cat)\n",
    "\n",
    "    # Creation des pipelines de preprocessing\n",
    "    num_pipe = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "    \n",
    "    # Ordinal (souvent mauvais pour modèles à distance/linéaires)\n",
    "    cat_pipe_ord = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),\n",
    "                              OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "    \n",
    "    pre_ord = ColumnTransformer([\n",
    "        (\"num\", num_pipe, num),\n",
    "        (\"cat\", cat_pipe_ord, cat)\n",
    "    ])\n",
    "    \n",
    "    # One-Hot (recommandé)\n",
    "    cat_pipe_ohe = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),\n",
    "                              OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    \n",
    "    pre_ohe = ColumnTransformer([\n",
    "        (\"num\", num_pipe, num),\n",
    "        (\"cat\", cat_pipe_ohe, cat)\n",
    "    ])\n",
    "\n",
    "    knn_ord = make_pipeline(pre_ord, KNeighborsClassifier(7))\n",
    "    knn_ohe = make_pipeline(pre_ohe, KNeighborsClassifier(7))\n",
    "    log_ord = make_pipeline(pre_ord, LogisticRegression(solver=\"saga\", max_iter=10000)) # solver \"saga\" gère les données dispersées (sparse) et est rapide pour les grands datasets\n",
    "    log_ohe = make_pipeline(pre_ohe, LogisticRegression(solver=\"saga\", max_iter=10000))\n",
    "    \n",
    "    models_encoding = {\n",
    "        \"KNN + OrdinalEnc\": knn_ord,\n",
    "        \"KNN + OneHotEnc\": knn_ohe,\n",
    "        \"LogReg + OrdinalEnc\": log_ord,\n",
    "        \"LogReg + OneHotEnc\": log_ohe,\n",
    "    }\n",
    "\n",
    "    for name, m in models_encoding.items():\n",
    "        acc = cross_val_score(m, X, y, cv=5, scoring=\"accuracy\").mean()\n",
    "        print(f\"{name:20s} -> {acc:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Impossible de télécharger Titanic via OpenML (hors-ligne ?).\")\n",
    "    print(\"Erreur:\", type(e).__name__, \"-\", str(e)[:120])\n",
    "    print(\"Astuce: remplace Titanic par un CSV local (Kaggle) et réutilise les mêmes pipelines.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev-teaching-hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
