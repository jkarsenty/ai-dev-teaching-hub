{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4230a1",
   "metadata": {},
   "source": [
    "# GridSearch + Validation croisée + Hyperparamètres (hors pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f7b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (142, 13) | Test shape: (36, 13)\n"
     ]
    }
   ],
   "source": [
    "## 4.0 Setup + data (Wine)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1) Dataset réel\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# 2) Split: train / test (le test ne sert qu'à la fin)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"| Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c749b0",
   "metadata": {},
   "source": [
    "## 4.1 Paramètres vs Hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ebd93",
   "metadata": {},
   "source": [
    "**Paramètres (learned / appris)** : appris pendant `.fit()`\n",
    "\n",
    "* Ex: coefficients `w` d’une régression logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e5f97",
   "metadata": {},
   "source": [
    "**Hyperparamètres (choisis / réglés)** : choisis avant l’entraînement\n",
    "\n",
    "* Ex: `n_neighbors` pour KNN, `C` (force de régularisation) pour LogisticRegression.\n",
    "\n",
    "Mini “preuve” : KNN n’a pas de paramètres appris (il mémorise), mais a des hyperparamètres (k, distance, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9b583",
   "metadata": {},
   "source": [
    "## 4.2 Version pas à pas : un “jeu de validation” (hold-out) pour choisir k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bb92dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtrain: (106, 13) | Val: (36, 13) | Test: (36, 13)\n"
     ]
    }
   ],
   "source": [
    "### Étape A — créer un validation set (train/val/test)\n",
    "\n",
    "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42, stratify=y_train\n",
    ")\n",
    "# -> 0.25 de train => ~20% total pour val (car X_train est 80% du total)\n",
    "\n",
    "print(\"Subtrain:\", X_subtrain.shape, \"| Val:\", X_val.shape, \"| Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3352e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Étape B — preprocessing manuel (fit scaler sur subtrain uniquement)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_subtrain_s = scaler.fit_transform(X_subtrain)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)  # on transformera le test avec le scaler appris sur subtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0b56d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur k (selon val): 7 | Accuracy val: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Étape C — grid search “manuel” sur k (hyperparamètre) en utilisant la validation\n",
    "\n",
    "k_values = range(1, 31)\n",
    "val_scores = []\n",
    "\n",
    "best_k = None\n",
    "best_val_acc = -1\n",
    "\n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_subtrain_s, y_subtrain)\n",
    "\n",
    "    y_val_pred = model.predict(X_val_s)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_scores.append(acc)\n",
    "\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_k = k\n",
    "\n",
    "print(\"Meilleur k (selon val):\", best_k, \"| Accuracy val:\", round(best_val_acc, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63f83b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test (final): 0.972\n"
     ]
    }
   ],
   "source": [
    "### Étape D — évaluation finale sur le test (une seule fois)\n",
    "\n",
    "final_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_model.fit(X_subtrain_s, y_subtrain)\n",
    "\n",
    "y_test_pred = final_model.predict(X_test_s)\n",
    "print(\"Accuracy test (final):\", round(accuracy_score(y_test, y_test_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110a0d8",
   "metadata": {},
   "source": [
    "#### Point clé :\n",
    "\n",
    "* Le **jeu de validation** sert à choisir l’hyperparamètre\n",
    "* Le **test** sert à estimer la performance “réelle” finale (1 seule fois)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba50ef",
   "metadata": {},
   "source": [
    "## 4.3 Validation croisée (CV) + grid search manuel (pas à pas sans pipeline)\n",
    "\n",
    "- Le hold-out (1 split) dépend beaucoup du hasard.  \n",
    "\n",
    "- La **validation croisée** fait plusieurs splits, et on moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c616485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Étape A — définir la CV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Étape B — grid search manuel CV **correct** (scaler refit à chaque fold)\n",
    "\n",
    "# **pourquoi pipeline existe** : sinon tu dois faire ça à la main pour éviter la fuite.\n",
    "\n",
    "\n",
    "def cv_score_knn_with_scaling(X, y, k, cv):\n",
    "    fold_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        pred = model.predict(X_va_s)\n",
    "        fold_scores.append(accuracy_score(y_va, pred))\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "k_values = range(1, 31)\n",
    "cv_scores = []\n",
    "\n",
    "best_k_cv = None\n",
    "best_cv_acc = -1\n",
    "\n",
    "for k in k_values:\n",
    "    acc = cv_score_knn_with_scaling(X_train, y_train, k, cv)\n",
    "    cv_scores.append(acc)\n",
    "    if acc > best_cv_acc:\n",
    "        best_cv_acc = acc\n",
    "        best_k_cv = k\n",
    "\n",
    "print(\"Meilleur k (CV):\", best_k_cv, \"| Accuracy CV:\", round(best_cv_acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Étape C — entraîner le modèle final sur tout le train, tester sur test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "final_knn = KNeighborsClassifier(n_neighbors=best_k_cv)\n",
    "final_knn.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Accuracy test:\", round(final_knn.score(X_test_s, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab3cc7",
   "metadata": {},
   "source": [
    "Messages clés :\n",
    "\n",
    "* CV = plus robuste qu’un seul split\n",
    "* Pour être “clean”, le preprocessing doit être refit **dans chaque fold**\n",
    "* C’est exactement ce que **Pipeline** automatise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0276f",
   "metadata": {},
   "source": [
    "## 4.4 “État de l’art” : `GridSearchCV` sur données déjà transformées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c6144",
   "metadata": {},
   "source": [
    "**Important** : si tu scales **une seule fois** avant la CV, tu crées une **fuite** (le scaler a “vu” toute la distribution du train, y compris les folds de validation).  \n",
    "\n",
    "Donc c’est “pratique”, mais **pas strictement correct** → c’est la passerelle parfaite pour justifier Pipeline ensuite.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b21024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version compacte :\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scaling une seule fois (pratique mais leakage pour la CV)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "\n",
    "param_grid = {\"n_neighbors\": list(range(1, 31))}\n",
    "grid = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "grid.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", round(grid.best_score_, 3))\n",
    "\n",
    "# test final\n",
    "X_test_s = scaler.transform(X_test)\n",
    "print(\"Test score:\", round(grid.score(X_test_s, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd40855",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "\n",
    "* `GridSearchCV` est top\n",
    "* **Mais** si tu veux une CV propre, il faut que le scaler soit “dans le loop” → donc **Pipeline** (partie suivante)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7935d",
   "metadata": {},
   "source": [
    "# 4.5 Bonus (hyperparamètre différent) : Logistic Regression et `C`\n",
    "\n",
    "Même structure, autre hyperparamètre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score_logreg_with_scaling(X, y, C, cv):\n",
    "    fold_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "\n",
    "        model = LogisticRegression(C=C, max_iter=5000, solver=\"lbfgs\")\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        pred = model.predict(X_va_s)\n",
    "        fold_scores.append(accuracy_score(y_va, pred))\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_acc = -1\n",
    "\n",
    "for C in C_values:\n",
    "    acc = cv_score_logreg_with_scaling(X_train, y_train, C, cv)\n",
    "    print(\"C =\", C, \"-> CV acc =\", round(acc, 3))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_C = C\n",
    "\n",
    "print(\"Meilleur C:\", best_C, \"| Best CV:\", round(best_acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9717bd",
   "metadata": {},
   "source": [
    "## Récapitulatif global des sujets abordés dans cette partie :\n",
    "\n",
    "* Différence **paramètres vs hyperparamètres**\n",
    "\n",
    "* Rôle du **jeu de validation**\n",
    "\n",
    "* Pourquoi le **test set** ne sert pas au tuning\n",
    "\n",
    "* Pourquoi **CV** est plus robuste\n",
    "\n",
    "* Pourquoi preprocessing + CV à la main devient pénible → **Pipeline** arrive naturellement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085b1e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev-teaching-hub (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
