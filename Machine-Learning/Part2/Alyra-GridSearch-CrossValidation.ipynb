{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ba0fa2",
   "metadata": {},
   "source": [
    "# GridSearch + Validation croisée + Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99a75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ebec3",
   "metadata": {},
   "source": [
    "## Pipeline + GridSearch (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdacaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params KNN: {'model__n_neighbors': 29}\n",
      "Best CV score: 0.979\n",
      "Test score: 0.972\n"
     ]
    }
   ],
   "source": [
    "pipe_knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"model__n_neighbors\": range(1, 31)\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    pipe_knn,\n",
    "    param_grid_knn,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params KNN:\", grid_knn.best_params_)\n",
    "print(\"Best CV score:\", round(grid_knn.best_score_, 3))\n",
    "print(\"Test score:\", round(grid_knn.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14589767",
   "metadata": {},
   "source": [
    "## Pipeline + GridSearch (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d429024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params LR: {'model__C': 1}\n",
      "Best CV score: 0.979\n",
      "Test score: 0.972\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    pipe_lr,\n",
    "    param_grid_lr,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params LR:\", grid_lr.best_params_)\n",
    "print(\"Best CV score:\", round(grid_lr.best_score_, 3))\n",
    "print(\"Test score:\", round(grid_lr.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129dbc4",
   "metadata": {},
   "source": [
    "### Ce que fait réellement GridSearchCV\n",
    "\n",
    "Pour chaque combinaison d’hyperparamètres :\n",
    "\n",
    "- Il applique la validation croisée\n",
    "\n",
    "- Il calcule le score moyen\n",
    "\n",
    "- Il compare les scores\n",
    "\n",
    "- Il sélectionne le meilleur\n",
    "\n",
    "- Il réentraîne sur tout le train avec la meilleure config\n",
    "\n",
    "**Donc :**\n",
    "\n",
    "> GridSearchCV = exploration systématique + validation croisée automatisée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b3a3c",
   "metadata": {},
   "source": [
    "## Comparer plusieurs modèles proprement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252016b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': {'best_params': {'model__n_neighbors': 29},\n",
       "  'cv_score': np.float64(0.9788177339901478),\n",
       "  'test_score': 0.9722222222222222},\n",
       " 'LogReg': {'best_params': {'model__C': 1},\n",
       "  'cv_score': np.float64(0.9790640394088669),\n",
       "  'test_score': 0.9722222222222222}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"KNN\": (pipe_knn, param_grid_knn),\n",
    "    \"LogReg\": (pipe_lr, param_grid_lr)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (pipe, grid) in models.items():\n",
    "    gs = GridSearchCV(pipe, grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    results[name] = {\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"cv_score\": gs.best_score_,\n",
    "        \"test_score\": gs.score(X_test, y_test)\n",
    "    }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c46a2",
   "metadata": {},
   "source": [
    "**Ici on observe :**\n",
    "\n",
    "- Comparaison équitable\n",
    "\n",
    "- Même jeu de données\n",
    "\n",
    "- Même CV\n",
    "\n",
    "- Même métrique\n",
    "\n",
    "> C’est une vraie logique “entreprise”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008060ea",
   "metadata": {},
   "source": [
    "## Le message fondamental (important pour le DL)\n",
    "\n",
    "> En ML, le cœur du travail n’est pas le modèle. C’est la méthode de validation.\n",
    "\n",
    "### En Deep Learning, ce sera exactement pareil :\n",
    "\n",
    "- On choisira learning rate\n",
    "\n",
    "- On choisira architecture\n",
    "\n",
    "- On choisira nombre de couches\n",
    "\n",
    "- On regardera la courbe validation\n",
    "\n",
    "- La validation est déjà introduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7aa99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
