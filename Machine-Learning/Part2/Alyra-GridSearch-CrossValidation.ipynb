{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ba0fa2",
   "metadata": {},
   "source": [
    "# GridSearch + Validation croisée + Hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26255eeb",
   "metadata": {},
   "source": [
    "## 0) Imports + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3ae789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (142, 13) Test: (36, 13)\n"
     ]
    }
   ],
   "source": [
    "# Dataset réel\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Split train/test (test = évaluation finale)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84a06b",
   "metadata": {},
   "source": [
    "## 1) Rappel : paramètres vs hyperparamètres (Markdown)\n",
    "\n",
    "- **Paramètres :** appris pendant fit (ex: poids d’un modèle linéaire).\n",
    "\n",
    "- **Hyperparamètres :** choisis avant fit (ex: k pour KNN, C pour Logistic Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed17f5e",
   "metadata": {},
   "source": [
    "## 2) Pourquoi la Cross-Validation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f7771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858334a5",
   "metadata": {},
   "source": [
    "KFold mais Stratified car en classification, on garde la proportion des classes similaire dans chaque fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ebec3",
   "metadata": {},
   "source": [
    "## 3) Exemple 1 — KNN : chercher le meilleur k avec GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5416ed",
   "metadata": {},
   "source": [
    "### 3.1 Pipeline (scaling + modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022a43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141f85e",
   "metadata": {},
   "source": [
    "### 3.2 Grille d’hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb75bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    \"model__n_neighbors\": range(1, 31)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3de96",
   "metadata": {},
   "source": [
    "### 3.3 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbdacaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres: {'model__n_neighbors': 29}\n",
      "Meilleur score CV: 0.979\n",
      "Score test final: 0.972\n"
     ]
    }
   ],
   "source": [
    "grid_knn = GridSearchCV(\n",
    "    estimator=pipe_knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres:\", grid_knn.best_params_)\n",
    "print(\"Meilleur score CV:\", round(grid_knn.best_score_, 3))\n",
    "print(\"Score test final:\", round(grid_knn.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392ac9b",
   "metadata": {},
   "source": [
    "#### Point clés :\n",
    "\n",
    "- GridSearch essaie tous les k\n",
    "\n",
    "- Pour chaque k, il fait une CV (5 entraînements)\n",
    "\n",
    "- Il moyenne les scores\n",
    "\n",
    "- Il garde le meilleur\n",
    "\n",
    "- Puis il évalue une seule fois sur le test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14589767",
   "metadata": {},
   "source": [
    "## 4) Exemple 2 — Logistic Regression : chercher le meilleur C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be031f0e",
   "metadata": {},
   "source": [
    "### 4.1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed47cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=5000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4233d",
   "metadata": {},
   "source": [
    "### 4.2 Grille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54328b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77173c5f",
   "metadata": {},
   "source": [
    "### 4.3 GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres:\", grid_lr.best_params_)\n",
    "print(\"Meilleur score CV:\", round(grid_lr.best_score_, 3))\n",
    "print(\"Score test final:\", round(grid_lr.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129dbc4",
   "metadata": {},
   "source": [
    "### Ce que fait réellement GridSearchCV\n",
    "\n",
    "Pour chaque combinaison d’hyperparamètres :\n",
    "\n",
    "- Il applique la validation croisée\n",
    "\n",
    "- Il calcule le score moyen\n",
    "\n",
    "- Il compare les scores\n",
    "\n",
    "- Il sélectionne le meilleur\n",
    "\n",
    "- Il réentraîne sur tout le train avec la meilleure config\n",
    "\n",
    "**Donc :**\n",
    "\n",
    "> GridSearchCV = exploration systématique + validation croisée automatisée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429024c",
   "metadata": {},
   "source": [
    "## 5) Comparer 2 modèles proprement (même protocole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67fe4a",
   "metadata": {},
   "source": [
    "### 5.1 Comparaison des GridSearch directement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_dict = {\n",
    "    \"KNN\": grid_knn,\n",
    "    \"LogReg\": grid_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06018ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, grid in grids_dict.items():\n",
    "    results[name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"cv_score\": grid.best_score_,\n",
    "        \"test_score\": grid.score(X_test, y_test)\n",
    "    }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7d38c",
   "metadata": {},
   "source": [
    "### 5.2 Comparaison des modèles (pipeline et grille à comparer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252016b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': {'best_params': {'model__n_neighbors': 29},\n",
       "  'cv_score': np.float64(0.9788177339901478),\n",
       "  'test_score': 0.9722222222222222},\n",
       " 'LogReg': {'best_params': {'model__C': 1},\n",
       "  'cv_score': np.float64(0.9790640394088669),\n",
       "  'test_score': 0.9722222222222222}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    # nom_du_model : (pipeline, grille)\n",
    "    \"KNN\": (pipe_knn, param_grid_knn),\n",
    "    \"LogReg\": (pipe_lr, param_grid_lr)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (pipe, grid) in models.items():\n",
    "    gs = GridSearchCV(pipe, grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    results[name] = {\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"cv_score\": gs.best_score_,\n",
    "        \"test_score\": gs.score(X_test, y_test)\n",
    "    }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c46a2",
   "metadata": {},
   "source": [
    "**Ici on observe :**\n",
    "\n",
    "- Comparaison équitable\n",
    "\n",
    "- Même jeu de données\n",
    "\n",
    "- Même CV\n",
    "\n",
    "- Même métrique\n",
    "\n",
    "- C’est une vraie logique “entreprise”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abe571",
   "metadata": {},
   "source": [
    "## Option (facultative) — RandomizedSearchCV\n",
    "\n",
    "### Quand la grille est énorme, on échantillonne au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "rand_knn = RandomizedSearchCV(\n",
    "    estimator=pipe_knn,\n",
    "    param_distributions={\"model__n_neighbors\": randint(1, 51)},\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rand_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params (random):\", rand_knn.best_params_)\n",
    "print(\"Best CV score:\", round(rand_knn.best_score_, 3))\n",
    "print(\"Test score:\", round(rand_knn.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd0c2b",
   "metadata": {},
   "source": [
    "## Récap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39ea21",
   "metadata": {},
   "source": [
    "- CV : robuste, réduit l’effet “split chanceux”\n",
    "\n",
    "- GridSearchCV : teste toutes les combinaisons\n",
    "\n",
    "- RandomizedSearchCV : teste un nombre limité de combinaisons aléatoires\n",
    "\n",
    "- Pipeline : garantit que le preprocessing est fait correctement dans chaque fold\n",
    "\n",
    "- Test set : une seule fois, à la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008060ea",
   "metadata": {},
   "source": [
    "## Message fondamental (important pour le DL)\n",
    "\n",
    "**En ML, le cœur du travail n’est pas le modèle. C’est la méthode de validation.**\n",
    "\n",
    "**En Deep Learning, ce sera exactement pareil :**\n",
    "\n",
    "- On choisira learning rate\n",
    "\n",
    "- On choisira architecture\n",
    "\n",
    "- On choisira nombre de couches\n",
    "\n",
    "- On regardera la courbe validation\n",
    "\n",
    "- La validation est déjà introduite."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
