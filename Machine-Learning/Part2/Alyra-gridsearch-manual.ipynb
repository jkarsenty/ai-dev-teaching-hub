{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbf78bc",
   "metadata": {},
   "source": [
    "# Notebook (sans Pipeline) — CV + Hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ea189",
   "metadata": {},
   "source": [
    "## 0) Imports + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e2ad8",
   "metadata": {},
   "source": [
    "## 1) Définir la cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978005cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée en 5 folds, avec conservation de la proportion des classes\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106f6a2",
   "metadata": {},
   "source": [
    "Sans pipeline, si tu fais :  \n",
    "scaler.fit_transform(X_train) puis GridSearchCV(...)\n",
    "\n",
    "\n",
    "Tu fais un preprocessing “global” avant la CV ⇒ **fuite de données** (data leakage).  \n",
    "La version correcte consiste à **refaire le scaling dans chaque fold**.  \n",
    "  \n",
    "Donc on va faire un mini “GridSearchCV maison” : même logique, mais on maîtrise le preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a2c77",
   "metadata": {},
   "source": [
    "## 2) GridSearch “maison” (sans pipeline) — KNN : chercher le meilleur k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da699260",
   "metadata": {},
   "source": [
    "### 2.1 Fonction : score CV pour une valeur de k (scaling refit à chaque fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_accuracy_knn_no_pipeline(X, y, k, cv):\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Scaling refit sur le train du fold uniquement (pas de fuite)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_va_s)\n",
    "        fold_scores.append(accuracy_score(y_va, y_pred))\n",
    "\n",
    "    return float(np.mean(fold_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213fd24",
   "metadata": {},
   "source": [
    "### 2.2 Recherche du meilleur k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 31)\n",
    "best_k, best_cv = None, -1\n",
    "\n",
    "for k in k_values:\n",
    "    score = cv_accuracy_knn_no_pipeline(X_train, y_train, k, cv)\n",
    "    if score > best_cv:\n",
    "        best_cv = score\n",
    "        best_k = k\n",
    "\n",
    "print(\"Meilleur k:\", best_k)\n",
    "print(\"Meilleur score CV:\", round(best_cv, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f754a4",
   "metadata": {},
   "source": [
    "### 2.3 Évaluation finale sur le test (une seule fois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler sur tout le train, puis test\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "final_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_knn.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Score test final:\", round(final_knn.score(X_test_s, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff27cf",
   "metadata": {},
   "source": [
    "## 3) Même chose — Logistic Regression : chercher le meilleur C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e736d",
   "metadata": {},
   "source": [
    "### 3.1 Fonction score CV (scaling refit à chaque fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_accuracy_logreg_no_pipeline(X, y, C, cv):\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr)\n",
    "        X_va_s = scaler.transform(X_va)\n",
    "\n",
    "        model = LogisticRegression(C=C, max_iter=5000)\n",
    "        model.fit(X_tr_s, y_tr)\n",
    "\n",
    "        y_pred = model.predict(X_va_s)\n",
    "        fold_scores.append(accuracy_score(y_va, y_pred))\n",
    "\n",
    "    return float(np.mean(fold_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630edd2",
   "metadata": {},
   "source": [
    "### 3.2 Recherche du meilleur C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1278b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_C, best_cv = None, -1\n",
    "\n",
    "for C in C_values:\n",
    "    score = cv_accuracy_logreg_no_pipeline(X_train, y_train, C, cv)\n",
    "    print(f\"C={C:<6} | CV acc={score:.3f}\")\n",
    "    if score > best_cv:\n",
    "        best_cv = score\n",
    "        best_C = C\n",
    "\n",
    "print(\"Meilleur C:\", best_C)\n",
    "print(\"Meilleur score CV:\", round(best_cv, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242b45a",
   "metadata": {},
   "source": [
    "### 3.3 Test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "final_lr = LogisticRegression(C=best_C, max_iter=5000)\n",
    "final_lr.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Score test final:\", round(final_lr.score(X_test_s, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b4df8",
   "metadata": {},
   "source": [
    "## 4) Mini récap : “Sans pipeline vs avec pipeline”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f69a4",
   "metadata": {},
   "source": [
    "* ### Sans pipeline :  \n",
    "  ✅ on peut faire propre, **mais** il faut gérer à la main :  \n",
    "\n",
    "  * le scaler **dans chaque fold**\n",
    "\n",
    "  * la répétition de code\n",
    " \n",
    "  * le risque d’erreurs / fuites\n",
    "\n",
    "* ### Avec pipeline :  \n",
    "  ✅ même logique, mais :  \n",
    "\n",
    "  * preprocessing automatiquement dans chaque fold\n",
    " \n",
    "  * `GridSearchCV` devient clean et compact\n",
    " \n",
    "  * c’est la norme en entreprise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
