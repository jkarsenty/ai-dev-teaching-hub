{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61f0520",
   "metadata": {},
   "source": [
    "## 0. Setup + dataset (Adult Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aaeff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Préprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Outils pipelines\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modèles\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics et évaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf0ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cols: 6 | Cat cols: 8\n"
     ]
    }
   ],
   "source": [
    "# 1) Chargement dataset réel : Adult (Census Income)\n",
    "adult = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "X = adult.data\n",
    "y = (adult.target == \">50K\").astype(int)  # binaire 0/1\n",
    "\n",
    "# 2) Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Colonnes num / cat\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns\n",
    "num_cols = X.columns.difference(cat_cols)\n",
    "\n",
    "print(\"Num cols:\", len(num_cols), \"| Cat cols:\", len(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091ffe1",
   "metadata": {},
   "source": [
    "## 1. Préprocessing manuel (hors pipeline) + modèle “hors pipeline”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f26aac",
   "metadata": {},
   "source": [
    "### 1.1 Imputer + scaler (num) / imputer + one-hot (cat), à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a711f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NUM : imputation + scaling (fit sur train, transform train/test)\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "num_scaler = StandardScaler()\n",
    "\n",
    "X_train_num = num_imputer.fit_transform(X_train[num_cols])\n",
    "X_test_num  = num_imputer.transform(X_test[num_cols])\n",
    "\n",
    "X_train_num = num_scaler.fit_transform(X_train_num)\n",
    "X_test_num  = num_scaler.transform(X_test_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cdbe7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CAT : imputation + one-hot\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "X_train_cat = cat_imputer.fit_transform(X_train[cat_cols])\n",
    "X_test_cat  = cat_imputer.transform(X_test[cat_cols])\n",
    "\n",
    "X_train_cat = ohe.fit_transform(X_train_cat)\n",
    "X_test_cat  = ohe.transform(X_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78613ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after preprocessing: (39073, 105)\n"
     ]
    }
   ],
   "source": [
    "# --- CONCAT (attention: sparse)\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_prepared = hstack([X_train_num, X_train_cat])\n",
    "X_test_prepared  = hstack([X_test_num,  X_test_cat])\n",
    "\n",
    "print(\"Shape after preprocessing:\", X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afecbf3",
   "metadata": {},
   "source": [
    "### 1.2 Modèle hors pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96700c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (manual preprocessing): 0.8521854846964889\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=5000, solver=\"saga\")\n",
    "clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_prepared)\n",
    "print(\"Accuracy (manual preprocessing):\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cda4a",
   "metadata": {},
   "source": [
    "**Remarques :**\n",
    "\n",
    "- “On doit se souvenir d’appliquer exactement les mêmes transfos au test”\n",
    "\n",
    "- “On doit faire fit uniquement sur train”\n",
    "\n",
    "- “C’est vite ingérable quand on fait de la CV / GridSearch”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f680ff",
   "metadata": {},
   "source": [
    "## 2. L’état de l’art : Pipeline, make_pipeline, ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5feec15",
   "metadata": {},
   "source": [
    "### 2.1 ColumnTransformer = préprocessing “par type de colonne”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac3596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_preprocess, num_cols),\n",
    "    (\"cat\", categorical_preprocess, cat_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192617c",
   "metadata": {},
   "source": [
    "> **Message clé :ColumnTransformer applique en parallèle des étapes différentes selon les colonnes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e01270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (manual preprocessing): 0.8521854846964889\n"
     ]
    }
   ],
   "source": [
    "# application du preprocessing via le pipeline.\n",
    "X_train_prepared = preprocess.fit_transform(X_train)\n",
    "X_test_prepared = preprocess.transform(X_test)\n",
    "\n",
    "# Modele\n",
    "clf = LogisticRegression(max_iter=5000, solver=\"saga\")\n",
    "clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred = clf.predict(X_test_prepared)\n",
    "print(\"Accuracy (manual preprocessing):\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab161c65",
   "metadata": {},
   "source": [
    "### 2.2 Pipeline (version explicite, nommée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b963ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Pipeline): 0.8521854846964889\n"
     ]
    }
   ],
   "source": [
    "# Création d'un pipeline complet : preprocessing + modèle\n",
    "pipe_lr = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=5000, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "# Entraînement du pipeline (fit sur train, transform + predict/score sur test)\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print(\"Accuracy (Pipeline):\", pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617dc7f8",
   "metadata": {},
   "source": [
    "> **Message clé : là, tu donnes au modèle les données brutes → le pipeline fait tout.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74dbb7",
   "metadata": {},
   "source": [
    "### 2.3 make_pipeline (raccourci)\n",
    "Même chose mais sans nommer toi-même les étapes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44199f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (make_pipeline): 0.8521854846964889\n"
     ]
    }
   ],
   "source": [
    "pipe_lr2 = make_pipeline(\n",
    "    preprocess,\n",
    "    LogisticRegression(max_iter=5000, solver=\"saga\")\n",
    ")\n",
    "\n",
    "pipe_lr2.fit(X_train, y_train)\n",
    "print(\"Accuracy (make_pipeline):\", pipe_lr2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7181eb",
   "metadata": {},
   "source": [
    "> **Message clé : make_pipeline = plus rapide, mais noms auto (pratique, moins lisible en GridSearch).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587669a3",
   "metadata": {},
   "source": [
    "> ### Best practice\n",
    "\n",
    " - Toujours mettre preprocessing dans un Pipeline\n",
    "\n",
    " - Utiliser ColumnTransformer pour données mixtes\n",
    "\n",
    " - Faire tuning / CV sur le pipeline, jamais sur données déjà transformées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ff7ea",
   "metadata": {},
   "source": [
    "## 3. Modèle dans le pipeline + plusieurs pipelines (modèles + preprocessing)\n",
    "\n",
    "### Vrai bénéfice : \n",
    "> **Il est possible de comparer plusieurs modèles facilement, et chacun peut avoir un preprocessing adapté.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2cb4d",
   "metadata": {},
   "source": [
    "### 3.1 Créer plusieurs pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc50af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"LogReg (scaled + OHE)\": Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=5000, solver=\"saga\"))\n",
    "    ]),\n",
    "    \n",
    "    # KNN = distance => scaling important (et OHE pour cat)\n",
    "    \"KNN (scaled + OHE)\": Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", KNeighborsClassifier(n_neighbors=15))\n",
    "    ]),\n",
    "    \n",
    "    # RandomForest = arbres => scaling pas nécessaire, mais OHE utile ici (sklearn)\n",
    "    # On peut faire un preprocess \"sans scaler\" pour illustrer\n",
    "}\n",
    "\n",
    "preprocess_no_scaler = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    (\"cat\", categorical_preprocess, cat_cols),\n",
    "])\n",
    "\n",
    "pipelines[\"RandomForest (no scale + OHE)\"] = Pipeline([\n",
    "    (\"preprocess\", preprocess_no_scaler),\n",
    "    (\"model\", RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a33dd",
   "metadata": {},
   "source": [
    "### 3.2 Comparaison propre en cross-validation (recommandé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d155bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg (scaled + OHE)          | acc CV: 0.851 ± 0.004\n",
      "KNN (scaled + OHE)             | acc CV: 0.841 ± 0.004\n",
      "RandomForest (no scale + OHE)  | acc CV: 0.852 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "for name, pipe in pipelines.items():\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(f\"{name:30s} | acc CV: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795cc86b",
   "metadata": {},
   "source": [
    "> #### Point clé :\n",
    "- Comparaison des pipelines complets (donc sans fuite)\n",
    "- c’est plug-and-play pour GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev-teaching-hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
